{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ExcelAutomation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luqmanrofifm/Excel_Table_Automation/blob/main/ExcelAutomation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X1-ErleuCi4"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from skimage.measure import label, regionprops\r\n",
        "from itertools import combinations "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0amQFtluSHD"
      },
      "source": [
        "def cleaningTable(data_path):\r\n",
        "\r\n",
        "    xl = pd.ExcelFile(data_path)\r\n",
        "    res = len(xl.sheet_names)\r\n",
        "\r\n",
        "    list_sheet = []\r\n",
        "\r\n",
        "    #=========read excel file\r\n",
        "    for i in xl.sheet_names:\r\n",
        "          df = pd.read_excel(data_path, sheet_name=i, engine='openpyxl')\r\n",
        "          list_sheet.append(df)\r\n",
        "\r\n",
        "    #=========remove sheet kosong\r\n",
        "    list_clean_sheet = []\r\n",
        "    for i in list_sheet:\r\n",
        "      size = i.shape\r\n",
        "      if ((size[0] == 0) and (size[1] == 0)):\r\n",
        "        continue\r\n",
        "      else:\r\n",
        "        list_clean_sheet.append(i)\r\n",
        "\r\n",
        "    #========parsing table\r\n",
        "    list_data = []\r\n",
        "    for i in list_clean_sheet:\r\n",
        "      list_data.append(parseTabel(i))\r\n",
        "    \r\n",
        "    #========remove None Row in table\r\n",
        "    for i in list_data:  \r\n",
        "      for index,y in enumerate(i):\r\n",
        "        i[index] = removeNoneRow(y)\r\n",
        "  \r\n",
        "\r\n",
        "    #========delete those that are not tables\r\n",
        "    #counter1 = 0\r\n",
        "    #counter2 = 0\r\n",
        "    list_clean_parsing = []\r\n",
        "    for i in list_data:\r\n",
        "      #print(counter1)\r\n",
        "      temporary = []\r\n",
        "      for y in i :\r\n",
        "        #print(counter2)\r\n",
        "        check = isItTable(y)\r\n",
        "        #print(check)\r\n",
        "        if (check):\r\n",
        "          temporary.append(y)\r\n",
        "          #continue\r\n",
        "        else:\r\n",
        "          continue\r\n",
        "      list_clean_parsing.append(temporary)\r\n",
        "\r\n",
        "    #========check duplicate table\r\n",
        "    #for i in list_data:\r\n",
        "    #  comb = combinations(i,2)\r\n",
        "    #  for y in comb:\r\n",
        "    #    return_similarity = similarityTable(y[0],y[1]) \r\n",
        "    #    if (return_similarity == 1):\r\n",
        "    #      continue\r\n",
        "    #    elif (return_similarity == 2):\r\n",
        "    #      return_data_similarity = checkSimilarityDataTable(y[1],y[0])\r\n",
        "    #      if (return_data_similarity):\r\n",
        "    #        i.remove(y[1])\r\n",
        "    #    else:\r\n",
        "    #      return_data_similarity = checkSimilarityDataTable(y[0],y[1])\r\n",
        "    #      if (return_data_similarity):\r\n",
        "    #        i.remove(y[0])\r\n",
        "    \r\n",
        "    for i in list_clean_parsing:\r\n",
        "      for index,y in enumerate(i):\r\n",
        "        i[index] = removeTitle(y)\r\n",
        "    \r\n",
        "    for i in list_clean_parsing:\r\n",
        "      for index,y in enumerate(i):\r\n",
        "        i[index] = checkMergedCell(y)\r\n",
        "\r\n",
        "    return list_clean_parsing\r\n",
        "    \r\n",
        "    #return list_data     "
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7kzQ2Ocu-oq"
      },
      "source": [
        "Method parseTabel merupakan method untuk memprediksi tabel apa saja yang terdapat pada file excel tersebut. Library yang digunakan untuk memprediksi adalah skimage.measure\r\n",
        "\r\n",
        "nilai kembaliannya berupa list yang berisi tabel-tabel setelah diparsing dalam bentuk data frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYsEnT-uuUXn"
      },
      "source": [
        "def parseTabel(data):\r\n",
        "    data_array = np.array(data.T.reset_index().values.T.tolist())\r\n",
        "    #binary_rep = np.array(data_array.notnull().astype('int'))\r\n",
        "    data_array_copy = data_array.copy()\r\n",
        "    size = data_array.shape\r\n",
        "\r\n",
        "    for i in range(size[0]):\r\n",
        "      for y in range(size[1]):\r\n",
        "        if (str(data_array[i,y]) == 'nan' or 'Unnamed' in str(data_array[i,y])):\r\n",
        "          data_array[i,y] = 0\r\n",
        "        else:\r\n",
        "          data_array[i,y] = 1\r\n",
        "\r\n",
        "\r\n",
        "    list_of_dataframes = []\r\n",
        "    l = label(data_array)\r\n",
        "\r\n",
        "    region = regionprops(l)\r\n",
        "    \r\n",
        "    for i in range(len(region)):\r\n",
        "      firstRow = region[i].bbox[0]\r\n",
        "\r\n",
        "      if (i < (len(region) - 1)):\r\n",
        "        secondRow = region[i+1].bbox[0]\r\n",
        "        if (firstRow == secondRow):\r\n",
        "          slice_data = data_array_copy[region[i].bbox[0]:region[i+1].bbox[2],region[i].bbox[1]:region[i+1].bbox[3]]\r\n",
        "          list_of_dataframes.append(pd.DataFrame(slice_data[1:], columns = slice_data[0]))\r\n",
        "        else:\r\n",
        "          slice_data = data_array_copy[region[i].bbox[0]:region[i].bbox[2],region[i].bbox[1]:region[i].bbox[3]]\r\n",
        "          list_of_dataframes.append(pd.DataFrame(slice_data[1:], columns = slice_data[0]))\r\n",
        "      else:\r\n",
        "        slice_data = data_array_copy[region[i].bbox[0]:region[i].bbox[2],region[i].bbox[1]:region[i].bbox[3]]\r\n",
        "        list_of_dataframes.append(pd.DataFrame(slice_data[1:], columns = slice_data[0]))\r\n",
        "\r\n",
        "      #counter = i+1\r\n",
        "      #while (counter < len(region)):\r\n",
        "      #  startColumn_test = region[counter].bbox[1]\r\n",
        "      #  lastRow_test = region[counter].bbox[2]\r\n",
        "        \r\n",
        "      #  if ((startColumn1 == startColumn_test) and (lastRow1 == lastRow_tes)):\r\n",
        "      #    continue \r\n",
        "      #  else\r\n",
        "\r\n",
        "\r\n",
        "    #for index,s in enumerate(regionprops(l)):\r\n",
        "        \r\n",
        "        #slice_data = data_array_copy[s.bbox[0]:s.bbox[2],s.bbox[1]:s.bbox[3]]\r\n",
        "        #list_of_dataframes.append(pd.DataFrame(slice_data[1:], columns = slice_data[0]))\r\n",
        "        #list_of_dataframes.append(data.iloc[s.bbox[0]:s.bbox[2],s.bbox[1]:s.bbox[3]])\r\n",
        "\r\n",
        "    list_parseTable = []\r\n",
        "\r\n",
        "    for i in list_of_dataframes:\r\n",
        "        if (isItTable(i)):\r\n",
        "            list_parseTable.append(i)\r\n",
        "        else:\r\n",
        "            continue\r\n",
        "\r\n",
        "    return list_parseTable"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4a13L-2vpC6"
      },
      "source": [
        "Method isItTable merupakan method yang berfungsi untuk mengecek apakah tiap tabel hasil parsing pada method parsTabel merupakan benar-benar tabel atau bukan.\r\n",
        "\r\n",
        "Logika yang digunakan untuk method ini adalah jika tabel tersebut memliki baris kurang dari atau sama dengan 1 maka otomatis bukan merupakan tabel. Lalu jika jika kondisi tersebut ternyata salah, maka kemudian akan dicek kembali. Jika baris dan kolom tabel tersebut kurang dari 2, maka otomatis bukan merupakan tabel\r\n",
        "\r\n",
        "Nilai kembalian dari method ini adalah boolean, artinya jika setelah dicek ternyata bukan tabel, maka nilai kembaliannya adalah \"False\". Kemudian sebaliknya, jika setelah dicek ternyata merupakan tabel, maka nilai kembaliannya adalah \"True\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhkTlph4uoPy"
      },
      "source": [
        "def isItTable(data):\r\n",
        "    row,column = data.shape\r\n",
        "\r\n",
        "    if (row <= 1):\r\n",
        "        return False\r\n",
        "    else:\r\n",
        "        if (row <= 2 and column <= 2):\r\n",
        "            return False\r\n",
        "        else:\r\n",
        "            return True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9ynPjlRx1YZ"
      },
      "source": [
        "Method checkSimilarityDataTable dan similarityTable merupakan method untuk membandingkan antara dua tabel apakah sama atau tidak. Hal ini dilakukan untuk mengatasi masalah ketika menjalankan method parseTabel, karena bisa saja ketika melakukan parsing, sebuah tabel bisa saja dipisah menjadi 2 tabel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLgrDgaD-KG1"
      },
      "source": [
        "def getIndexColumn(data):\r\n",
        "  \r\n",
        "  list_index_column = []\r\n",
        "  for i in data:\r\n",
        "    try:\r\n",
        "       a = int(i)\r\n",
        "       list_index_column.append(a)\r\n",
        "    except:\r\n",
        "      continue\r\n",
        "  #print(list_index_column)\r\n",
        "  result = 0\r\n",
        "\r\n",
        "  if (len(list_index_column) <= 1):\r\n",
        "    result = False\r\n",
        "    #print('False 1')\r\n",
        "  else:\r\n",
        "    different_value = list_index_column[1] - list_index_column[0]\r\n",
        "\r\n",
        "    for i in range(len(list_index_column)-1):\r\n",
        "      #print(i)\r\n",
        "      check = (i+1) - i\r\n",
        "      if (check != different_value):\r\n",
        "        result = False\r\n",
        "        #print('False 2')\r\n",
        "        break\r\n",
        "      else:\r\n",
        "        if ((i+1) == len(list_index_column)-1):\r\n",
        "          if (list_index_column[0] >= 1000):\r\n",
        "            result = False\r\n",
        "          else:\r\n",
        "            result = True\r\n",
        "          #print('True')\r\n",
        "  \r\n",
        "  return result\r\n",
        "\r\n",
        "def getNoneRow(data):\r\n",
        "  list_noneData = []\r\n",
        "  counter = 0\r\n",
        "  \r\n",
        "  for i in data:\r\n",
        "    if (str(i) == 'nan' or 'Unnamed' in str(i)):\r\n",
        "      list_noneData.append(counter)\r\n",
        "    counter += 1\r\n",
        "  \r\n",
        "  if (len(list_noneData) ==  len(data)):\r\n",
        "    return True\r\n",
        "  else:\r\n",
        "    return False\r\n",
        "\r\n",
        "def removeNoneRow(data):\r\n",
        "  data_array = np.array(data.T.reset_index().values.T.tolist())\r\n",
        "  data_result = []\r\n",
        "\r\n",
        "  for i in range(len(data_array)):\r\n",
        "    if (getNoneRow(data_array[i,:]) or getIndexColumn(data_array[i,:])):\r\n",
        "      #print('halo')\r\n",
        "      continue\r\n",
        "    else:\r\n",
        "      data_result.append(data_array[i,:])\r\n",
        "\r\n",
        "  result = np.array(data_result)\r\n",
        "\r\n",
        "  return pd.DataFrame(result[1:], columns = result[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xNK4oF7u1ct"
      },
      "source": [
        "def checkSimilarityDataTable(table1, table2):\r\n",
        "  np_array1 = np.array(table1.T.reset_index().values.T.tolist())\r\n",
        "  np_array2 = np.array(table2.T.reset_index().values.T.tolist())\r\n",
        "\r\n",
        "  rowSize1 = np_array1.shape[0]\r\n",
        "  columnSize1 = np_array1.shape[1]\r\n",
        "  rowSize2 = np_array2.shape[0]\r\n",
        "  columnSize2 = np_array2.shape[1]\r\n",
        "  \r\n",
        "  number_true_value = 0\r\n",
        "  counter = 0\r\n",
        "  for i in range(rowSize1):\r\n",
        "    for j in range(columnSize1):\r\n",
        "      loc = np.where(np_array2 == np_array1[i,j])\r\n",
        "      if (len(loc[0]) != 0):\r\n",
        "        #print('True')\r\n",
        "        counter += 1\r\n",
        "\r\n",
        "  result = counter / (rowSize1*columnSize1)\r\n",
        "  if (result == 1):\r\n",
        "    return True\r\n",
        "    #print('True')\r\n",
        "  else: \r\n",
        "    return False\r\n",
        "    #print('False')\r\n",
        "\r\n",
        "def similarityTable(table1, table2):\r\n",
        "  np_array1 = np.array(table1.T.reset_index().values.T.tolist())\r\n",
        "  np_array2 = np.array(table2.T.reset_index().values.T.tolist())\r\n",
        "\r\n",
        "  check1 = 0\r\n",
        "  check2 = 0\r\n",
        "\r\n",
        "  rowSize1 = np_array1.shape[0]\r\n",
        "  columnSize1 = np_array1.shape[1]\r\n",
        "  rowSize2 = np_array2.shape[0]\r\n",
        "  columnSize2 = np_array2.shape[1]\r\n",
        "\r\n",
        "  #===== check table1 in table2\r\n",
        "  if (np_array2.shape[0] > np_array1.shape[0]):\r\n",
        "    if (np_array1.shape[1] > np_array2.shape[1]):\r\n",
        "      check1 = False\r\n",
        "      #print(\"hai\")\r\n",
        "    else:\r\n",
        "      startValue = np_array1[0,0]\r\n",
        "      loc = np.where(np_array2 == startValue)\r\n",
        "      for i in range(len(loc[0])):\r\n",
        "        startRow = loc[0][i]\r\n",
        "        startColumn = loc[1][i]\r\n",
        "        selectedArray = np_array2[startRow:(startRow + rowSize1),startColumn:(startColumn + columnSize1)]\r\n",
        "        rowSelectedArray = selectedArray.shape[0]\r\n",
        "        columnSelectedArray = selectedArray.shape[1]        \r\n",
        "        if ((rowSize1 == rowSelectedArray) and (columnSize1 == columnSelectedArray)):\r\n",
        "        #print('True')\r\n",
        "          check1 = True\r\n",
        "        else:\r\n",
        "        #print('False')\r\n",
        "          check1 = False\r\n",
        "  \r\n",
        "  #=========== check table2 in table1\r\n",
        "  if (np_array1.shape[0] > np_array2.shape[0]):\r\n",
        "    if (np_array2.shape[1] > np_array1.shape[1]):\r\n",
        "      check2 = False\r\n",
        "    else:\r\n",
        "      startValue = np_array2[0,0]\r\n",
        "      loc = np.where(np_array1 == startValue)\r\n",
        "      for i in range(len(loc[0])):\r\n",
        "        startRow = loc[0][i]\r\n",
        "        startColumn = loc[1][i]\r\n",
        "        selectedArray = np_array1[startRow:(startRow + rowSize2),startColumn:(startColumn + columnSize2)]\r\n",
        "        #print(selectedArray)\r\n",
        "        rowSelectedArray = selectedArray.shape[0]\r\n",
        "        columnSelectedArray = selectedArray.shape[1]        \r\n",
        "        if ((rowSize2 == rowSelectedArray) and (columnSize2 == columnSelectedArray)):\r\n",
        "        #print('True')\r\n",
        "          check2 = True\r\n",
        "        else:\r\n",
        "        #print('False')\r\n",
        "          check2 = False\r\n",
        "\r\n",
        "  if (check1 == False):\r\n",
        "    if (check2 == False):\r\n",
        "      #print(\"nggak ada yang sama\")\r\n",
        "      return 1\r\n",
        "    else:\r\n",
        "      #print(\"tabel 2 masuk tabel 1\")\r\n",
        "      return 2\r\n",
        "  else:\r\n",
        "    #print(\"tabel 1 masuk tabel 2\")\r\n",
        "    return 3\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCe2PQKm1yjc"
      },
      "source": [
        "Mehtod removeTitle merupakan method yang berfungsi untuk mendeteks judul yang ada pada tabel tersebut kemudian menghapusnya"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IC0iQyXu5mG"
      },
      "source": [
        "def removeTitle(data):\r\n",
        "  result = []\r\n",
        "  data_array = np.array(data.T.reset_index().values.T.tolist())\r\n",
        "  checkTitle, listIndex, data = 0, 0, 0\r\n",
        "\r\n",
        "  counter = 0\r\n",
        "  for i in range(len(data_array)):\r\n",
        "    #print(counter)\r\n",
        "    checkTitle,listIndex = checkNoneData(data_array[i,:], (len(data_array[i,:])))\r\n",
        "\r\n",
        "    if (checkTitle):\r\n",
        "      if (i < (len(data_array)-1)):\r\n",
        "        if (matchingRow(data_array[i,:], data_array[i+1,:])):\r\n",
        "          if (checkTitle):\r\n",
        "            continue\r\n",
        "          else:\r\n",
        "            result.append(data_array[i,:])\r\n",
        "        else:\r\n",
        "          if (i < (len(data_array)-2)):\r\n",
        "            if (matchingRow3Layer(data_array[i,:], data_array[i+1,:], data_array[i+2,:])):\r\n",
        "              if (checkTitle):\r\n",
        "                continue\r\n",
        "              else:\r\n",
        "                result.append(data_array[i,:])\r\n",
        "            else:\r\n",
        "              continue\r\n",
        "          else:\r\n",
        "            continue\r\n",
        "      else:\r\n",
        "        continue\r\n",
        "    else:\r\n",
        "      result.append(data_array[i,:])\r\n",
        "    counter += 1\r\n",
        "\r\n",
        "  return pd.DataFrame(result[1:], columns = result[0])\r\n",
        "\r\n",
        "def checkNoneData(listData, length):\r\n",
        "  counter = 0\r\n",
        "  list_index = []\r\n",
        "  data = 0\r\n",
        "\r\n",
        "  for i in listData:\r\n",
        "    if (str(i) == 'nan' or 'Unnamed' in str(i)):\r\n",
        "      list_index.append(counter)\r\n",
        "    counter += 1\r\n",
        "\r\n",
        "  booleanResult = 0\r\n",
        "  \r\n",
        "  if ((length-1) in list_index and len(listData) > 3):\r\n",
        "    if ((list_index[-1]-list_index[0]+1) == len(list_index)):\r\n",
        "      booleanResult = True\r\n",
        "    else:\r\n",
        "      booleanResult = False\r\n",
        "  else:\r\n",
        "   booleanResult = False\r\n",
        "  \r\n",
        "  return booleanResult, list_index\r\n"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w03Sfb9O2gYp"
      },
      "source": [
        "Method checkMergeCell merupakan method yang berfungsi untuk menghapus adanya merge cell pada tabel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnQ_oRt3u7wR"
      },
      "source": [
        "def checkMergedCell(data):\r\n",
        "  data_array = np.array(data.T.reset_index().values.T.tolist())\r\n",
        "\r\n",
        "  #print(matchingRow(data_array[0,:],data_array[1,:]))\r\n",
        "\r\n",
        "  if (matchingRow(data_array[0,:],data_array[1,:])):\r\n",
        "    #print(1)\r\n",
        "    data_array[0,:] = renameHeader(data_array[0,:], data_array[1,:])\r\n",
        "    \r\n",
        "    data_result = np.delete(data_array,1,0)\r\n",
        "    return pd.DataFrame(data_result[1:], columns = data_result[0])\r\n",
        "\r\n",
        "  elif (matchingRow3Layer(data_array[0,:],data_array[1,:], data_array[2,:])):\r\n",
        "    #print(2)\r\n",
        "    data_array[1,:] = renameHeader(data_array[1,:], data_array[2,:])\r\n",
        "    data_array[0,:] = renameHeader(data_array[0,:], data_array[1,:])\r\n",
        "    \r\n",
        "    data_result = np.delete(data_array,[1,2],0)\r\n",
        "    return pd.DataFrame(data_result[1:], columns = data_result[0])\r\n",
        "  elif (checkColumnMerge(data_array[0,:],data_array[1,:])[0]):\r\n",
        "    index = checkColumnMerge(data_array[0,:],data_array[1,:])[1]\r\n",
        "    counter = 1\r\n",
        "    for i in index:\r\n",
        "      data_array[0,i] = data_array[0,i-1] + \"_\" + str(counter)\r\n",
        "      counter += 1\r\n",
        "    \r\n",
        "    data_array[0,:] = renameHeader(data_array[0,:], data_array[1,:])\r\n",
        "    \r\n",
        "    data_result = np.delete(data_array,1,0)\r\n",
        "    return pd.DataFrame(data_result[1:], columns = data_result[0])\r\n",
        "  else:\r\n",
        "    #print(3)\r\n",
        "    return pd.DataFrame(data_array[1:], columns = data_array[0])\r\n",
        "\r\n",
        "def checkColumnMerge(data1, data2):\r\n",
        "  None1, NonNull1 = getNoneIndex(data1)\r\n",
        "  None2, NonNull2 = getNoneIndex(data2)\r\n",
        "\r\n",
        "  list_index_noncover = []\r\n",
        "  for i in None1:\r\n",
        "    if (i in None2):\r\n",
        "      list_index_noncover.append(i)\r\n",
        "  \r\n",
        "  index_merge = []\r\n",
        "  for i in None1:\r\n",
        "    if (i in NonNull2):\r\n",
        "      continue\r\n",
        "    else:\r\n",
        "      index_merge.append(i)\r\n",
        "\r\n",
        "  list_column_merge = []\r\n",
        "  for i in index_merge:\r\n",
        "    if (i in list_index_noncover):\r\n",
        "      list_column_merge.append(i)\r\n",
        "\r\n",
        "  if (len(list_column_merge) == 0):\r\n",
        "    return False,0\r\n",
        "  else:\r\n",
        "    return True,list_column_merge\r\n",
        "\r\n",
        "def matchingRow(data1, data2):\r\n",
        "  None1, NonNull1 = getNoneIndex(data1)\r\n",
        "  None2, NonNull2 = getNoneIndex(data2)\r\n",
        "  #print(None1)\r\n",
        "  #print(NonNull2)\r\n",
        "  #print(None2)\r\n",
        "  #print(NonNull1)\r\n",
        "  check1 = checkIndex(None1, NonNull2)\r\n",
        "  check2 = checkIndex(None2, NonNull1)\r\n",
        "  if (check1 and check2):\r\n",
        "    return True\r\n",
        "  else:\r\n",
        "    return False\r\n",
        "\r\n",
        "#==== Tambahan 1.0 ========================================================\r\n",
        "def matchingRow3Layer(data1, data2, data3):\r\n",
        "  None1, NonNull1 = getNoneIndex(data1)\r\n",
        "  None2, NonNull2 = getNoneIndex(data2)\r\n",
        "  None3, NonNull3 = getNoneIndex(data3)\r\n",
        "  \r\n",
        "  list_null_cover = []\r\n",
        "  list_null_nonCover = []\r\n",
        "  counter = 0\r\n",
        "  result = 0\r\n",
        "\r\n",
        "  for i in None3:\r\n",
        "    if (i in NonNull2):\r\n",
        "      list_null_cover.append(counter)\r\n",
        "    else:\r\n",
        "      list_null_nonCover.append(counter)\r\n",
        "    \r\n",
        "    counter += 1\r\n",
        "  \r\n",
        "  listBoolean = []\r\n",
        "  for i in NonNull1:\r\n",
        "    if (i in NonNull2):  \r\n",
        "      cek1 = 1\r\n",
        "    else:\r\n",
        "      cek1 = 2\r\n",
        "\r\n",
        "    if (i in NonNull3):\r\n",
        "      cek2 = 1\r\n",
        "    else:\r\n",
        "      cek2 = 2 \r\n",
        "\r\n",
        "    if ((cek1 == cek2)):\r\n",
        "      listBoolean.append(1)\r\n",
        "    else:\r\n",
        "      listBoolean.append(2)  \r\n",
        "  \r\n",
        "  if (2 in listBoolean):\r\n",
        "    result = False\r\n",
        "  else:\r\n",
        "    result = True  \r\n",
        "  \r\n",
        "  if (len(None3) == 0):\r\n",
        "    return False\r\n",
        "  else:\r\n",
        "    if (result):\r\n",
        "      for i in None2:\r\n",
        "        if (i in NonNull3):\r\n",
        "          return True\r\n",
        "        elif (i in list_null_nonCover):\r\n",
        "          return True\r\n",
        "        else:\r\n",
        "          return False\r\n",
        "    else:\r\n",
        "    #print('False 2')\r\n",
        "      return False\r\n",
        "    \r\n",
        "#================================================================================\r\n",
        "\r\n",
        "def getNoneIndex(listData):\r\n",
        "  counter = 0 \r\n",
        "  listIndexNone = []\r\n",
        "  listIndexNonNull = []\r\n",
        "  for i in listData:\r\n",
        "    if (str(i) == 'nan' or 'Unnamed' in str(i)):\r\n",
        "      listIndexNone.append(counter)\r\n",
        "    else:\r\n",
        "      listIndexNonNull.append(counter)\r\n",
        "    counter += 1\r\n",
        "  return listIndexNone, listIndexNonNull\r\n",
        "\r\n",
        "def checkIndex(dataNull, dataNonNull):\r\n",
        "  for i in dataNull:\r\n",
        "    if (i in dataNonNull):\r\n",
        "      return True\r\n",
        "    else:\r\n",
        "      return False\r\n",
        "      break\r\n",
        "\r\n",
        "def renameHeader(data1, data2):\r\n",
        "  indexNull1, indexNonNull1 = getNoneIndex(data1)\r\n",
        "  indexNull2, indexNonNull2 = getNoneIndex(data2)\r\n",
        "\r\n",
        "  duplicate_index = []\r\n",
        "  data = data1.copy()\r\n",
        "\r\n",
        "  for i in indexNonNull1:\r\n",
        "    if (i in indexNonNull2):\r\n",
        "      duplicate_index.append(i)\r\n",
        "\r\n",
        "  for i in range(len(data1)):\r\n",
        "    if (i in duplicate_index):\r\n",
        "      data[i] = str(data2[i]) + \"(\" + str(data1[i]) + \")\"\r\n",
        "    elif ((i in indexNull1) and (i in indexNull2)):\r\n",
        "      continue\r\n",
        "    elif (i in indexNull1):\r\n",
        "      index = findIndexMergedCell(duplicate_index, i)\r\n",
        "      #print(index)\r\n",
        "      data[i] = str(data2[i]) + \"(\" + str(data1[index]) + \")\"\r\n",
        "    else:\r\n",
        "      continue\r\n",
        "  \r\n",
        "  return data\r\n",
        "\r\n",
        "\r\n",
        "def findIndexMergedCell(duplicateIndex, index):\r\n",
        "\r\n",
        "  for i in range(len(duplicateIndex)):\r\n",
        "    if (index == duplicateIndex[i]):\r\n",
        "      return index\r\n",
        "      break\r\n",
        "    else:\r\n",
        "      if (i != (len(duplicateIndex)-1)):\r\n",
        "        if (index > duplicateIndex[i] and index < duplicateIndex[i+1]):\r\n",
        "          return duplicateIndex[i]\r\n",
        "        else:\r\n",
        "          continue\r\n",
        "      else:\r\n",
        "        if (index > duplicateIndex[i]):\r\n",
        "          return duplicateIndex[i]"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE5chHhi1tAm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "2422cda4-910e-41ee-9908-9899c1518c3b"
      },
      "source": [
        "coba = cleaningTable('/content/DATA_DUMMY_MEDICAL_revisi.xlsx')\r\n",
        "coba[0][2]"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NO</th>\n",
              "      <th>NRP</th>\n",
              "      <th>NAME PSS</th>\n",
              "      <th>LOC.</th>\n",
              "      <th>LOC._1</th>\n",
              "      <th>OBAT(TAHUN 2020 (JAN</th>\n",
              "      <th>RS(TAHUN 2020 (JAN-N</th>\n",
              "      <th>KACAMATA(TAHUN 2020</th>\n",
              "      <th>TOTAL(TAHUN 2020 (JA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>0101012</td>\n",
              "      <td>NAMA PSS 1</td>\n",
              "      <td>HO</td>\n",
              "      <td>nan</td>\n",
              "      <td>5500000</td>\n",
              "      <td>80000000</td>\n",
              "      <td>0</td>\n",
              "      <td>85500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>0101013</td>\n",
              "      <td>NAMA PSS 2</td>\n",
              "      <td>HO</td>\n",
              "      <td>nan</td>\n",
              "      <td>1000000</td>\n",
              "      <td>0</td>\n",
              "      <td>10000000</td>\n",
              "      <td>11000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  NO      NRP  ... KACAMATA(TAHUN 2020  TOTAL(TAHUN 2020 (JA\n",
              "0  3  0101012  ...                    0             85500000\n",
              "1  4  0101013  ...             10000000             11000000\n",
              "\n",
              "[2 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPO-Htwa1vzI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a24fe94d-8e0d-47a3-fed4-21b9ab87bb84"
      },
      "source": [
        "#tes = removeTitle(coba[0][0])\r\n",
        "#tes"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMhp7FHD6l7A"
      },
      "source": [
        "#cek = cleaningTable(\"/content/DATA_DUMMY_Productivity_BC_as_of_30_Nov_2020.xlsx\")\n",
        "#cek[0][2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tRaNiPcLHHT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}